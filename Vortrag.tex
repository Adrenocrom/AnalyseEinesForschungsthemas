\documentclass[xcolor=dvipsnames]{beamer}

\usepackage{default}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{import}
\usepackage{color}
\usepackage{amsmath,lipsum}
\usepackage{xcolor}
\usepackage{url}
\usepackage{tikz}
\usepackage[backend=biber]{biblatex}
\usepackage{caption}
\captionsetup[figure]{labelformat=empty}

\bibliography{literatur.bib}

\usetikzlibrary{positioning,shapes,3d}

\tikzset{
  every overlay node/.style={}
}
\def\tikzoverlay{%
   \tikz[baseline,overlay]\node[every overlay node]
}%

\usetheme{boxes}

\definecolor{light-gray}{gray}{0.90}

%\bibliographystyle{plain}
\makeatother
\setbeamertemplate{sections/subsections in toc}[ball]
\setbeamertemplate{footline}
{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.6\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    % %\usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle\hspace*{3em}
    \insertframenumber{} / \inserttotalframenumber\hspace*{1ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}
\makeatletter
\setbeamertemplate{navigation symbols}{}

\title{Analyse eines Forschungsthemas}
\author{Josef Schulz}
\date{\today}

\begin{document}
%\pgfdeclarelayer{background}
%\pgfsetlayers{background,main}

\begin{frame}
	\begin{center}
		\Large
		\textcolor{blue}{Analyse eines Forschungsthemas}
		
		\normalsize
		\vspace{0.2cm}
		a detection and two pose estimation algoritms deal with occlusion
		
		\vspace{1cm}
		Josef Schulz
		
		\vspace{1cm}
		\today
	\end{center}
\end{frame}

\section{Examples}
\begin{frame}
	\frametitle{Examples Problems}
	\begin{onlyenv}<2->
		\begin{tikzpicture}[remember picture,overlay]  
			\node [xshift=-10cm,yshift=1.5cm] at (current page.east) {
				\parbox{.5\textwidth}{
					\begin{figure}
						\includegraphics[width=5cm]{img/examples2.png}
						\caption{DPM: classification and localisation}
					\end{figure}
				}
			};
		\end{tikzpicture}
	\end{onlyenv}
	\begin{onlyenv}<3->
		\begin{tikzpicture}[remember picture,overlay]  
			\node [xshift=-8cm,yshift=-2.2cm] at (current page.east) {
				\parbox{.5\textwidth}{
					\begin{figure}
						\includegraphics[width=4cm]{img/examples1.png}
						\caption{joint pose estimation with Kinect2 SDK}
					\end{figure}
				}
			};
		\end{tikzpicture}
	\end{onlyenv}
	
	\begin{onlyenv}<4->
		\begin{tikzpicture}[remember picture,overlay]  
			\node [xshift=-3cm,yshift=1cm] at (current page.east) {
				\parbox{.5\textwidth}{
					\begin{figure}
						\includegraphics[width=5cm]{img/examples3.png}
						\caption{pose estimation with occlusion}
					\end{figure}
				}
			};
		\end{tikzpicture}
	\end{onlyenv}

\end{frame}

\begin{frame}{Content}
	\large
	\tableofcontents[subsubsectionstyle=hide]
\end{frame}

\section{Algorithms}
\subsection{Semantic Occlusion Model}
{\setbeamercolor{background canvas}{bg=light-gray}
\begin{frame}
	\frametitle{A Semantic Occlusion Model For Human Pose Estimation}
	\vline
	\Large

	\begin{figure}
		\includegraphics[width=5cm]{img/HPE.png}
		\caption{Kinect2 SDK}
	\end{figure}
		
	\begin{align*}
		\textcolor{blue}{Input}&:  \text{single Depth-Image} \\
		\textcolor{purple}{Output}&: \text{estimated poses of all parts}
	\end{align*}
\end{frame}}

\subsubsection{Introduction}


\subsubsection{Algorithm}
\begin{frame}
	\frametitle{Regression Forest}
	
	\begin{columns}
		\begin{column}{.5\textwidth}
			
			\begin{center}
				\Large
				Training Set
				
				\vspace{0.6cm}
				
				\normalsize
	
				$Q = \{(q, D, c, \{V_j\}), ...\}$
			\end{center}
			
			
			\vspace{0.6cm}
			
			
			\begin{itemize}
			    \item[$q$] pixel location
			    \item[$D$] reference depth image
			    \item[$c$] class label corresponding to limbs
			    \item[$\{V_j\}$] is set of 3D offset vectors between $q$ and the joint position $q_j$:
			    	\begin{itemize}
				    	\item[] $V_j = q_j - q$
			    	\end{itemize}
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{figure}
					\begin{tikzpicture} [scale=.9,
										 split/.style = {fill=SkyBlue!40, draw, align=center, regular polygon, regular polygon sides=3},
										 leaf/.style = {fill=gray!10, circle, draw, align=center, inner sep=0pt},
										 train/.style = {fill=LimeGreen!40, rectangle, align=center, draw, rounded corners=6pt}]
						\node[train] (t1) at (0, 1.5) {$Q = \{(q,D,c,\{V_j\})\}$};
						\node[split] (s1) at (0, 0) {$\gamma_0$};
						\node[train] (t2) at (-1.5, -1.2) {$Q_0$};
						\node[train] (t3) at (1.5, -1.2) {$Q_1$};
						\node[split] (s2) at (-1.5, -3) {$\gamma_1$};
						\node[split] (s3) at ( 1.5, -3) {$\gamma_2$};
						\node[leaf] (l1) at (-2.5, -5) {\small $p_j(V|l)$};
						\node[leaf] (l2) at (-0.75, -5) {\small $p_j(V|l)$};
						\node[leaf] (l3) at ( 0.75, -5) {\small $p_j(V|l)$};
						\node[leaf] (l4) at ( 2.5, -5) {\small $p_j(V|l)$};
						
						\draw[->,thick,draw=black!50] (t1.south) to (s1.north) ;
						\draw[->,thick,draw=black!50] (s1.south west) to [out=270,in=90] (t2.north);
						\draw[->,thick,draw=black!50] (s1.south east) to [out=270,in=90] (t3.north);
						\draw[->,thick,draw=black!50] (t2.south) to (s2.north) ;
						\draw[->,thick,draw=black!50] (t3.south) to (s3.north) ;
						\draw[->,thick,draw=black!50] (s2.south west) to [out=270,in=90] (l1.north);
						\draw[->,thick,draw=black!50] (s2.south east) to [out=270,in=90] (l2.north);
						\draw[->,thick,draw=black!50] (s3.south west) to [out=270,in=90] (l3.north);
						\draw[->,thick,draw=black!50] (s3.south east) to [out=270,in=90] (l4.north);
					\end{tikzpicture}	
				\end{figure}
		\end{column}
	\end{columns}
	
\end{frame}

\begin{frame}
	\frametitle{Split Node}
	\Large
	
	\begin{center}
		\huge
		$\textcolor{violet}{\gamma} = (\textcolor{blue}{u}, \textcolor{blue}{v}, \textcolor{blue}{\tau})$
	\end{center}
	
	\vspace{1cm}
	
	
	
	$\Phi_{\textcolor{violet}{\gamma}}(q, D) \mapsto \{0, 1\}$
	
	\vspace{0.5cm}
	
	$\Phi_{\textcolor{violet}{\gamma}}(q, D) = \begin{cases}
	1 & \mbox{if } D(q + \frac{\textcolor{blue}{u}}{D(q)}) - D(q + \frac{\textcolor{blue}{v}}{D(q)}) > \textcolor{blue}{\tau} \\
	0 & \mbox{else}
	\end{cases}$
	
	\vspace{1cm}
	\begin{itemize}
		\item[$\textcolor{blue}{u}, \textcolor{blue}{v}$ - ] offset vectors
		\item[$\textcolor{blue}{\tau}$ - ] threshold
		\item[$D(q)$ - ] depth value
	\end{itemize}
	

\end{frame}

\begin{frame}
	\frametitle{Evaluating The Splitting Functions Information Gain}
	\large

	\vspace{1cm}
	$\Phi^* = \arg\max_\Phi g(\Phi)$
	\vspace{1cm}
	
	$g(\Phi) = H(Q) - \sum\limits_{s \in \{0, 1\}}^{} \frac{\vert Q_s(\Phi) \vert}{\vert Q \vert} H(Q_s(\Phi))$
	\vspace{1cm}
	
	$H(Q) = - \sum\limits_{c}^{} p(c | Q) \log( p(c | Q) )$
	
	\vspace{1cm}
	\normalsize
	\begin{itemize}
		\item[$H(Q)$ - ] Shannon entropy
		\item[$g(\Phi)$ - ] information gain
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Leaf Node}
	\large
	
	a leaf node stores:
	\begin{itemize}
		\item class $c$
		\item two cluster centers $V_{ljk}$ for each joint
		\item two support values $w_{ljk}$ for each cluster
		\item probabilities over $V_j$:
	\end{itemize}
	
	\begin{equation*}
		p_j(V | l) \propto \sum\limits_{k \in K}^{} w_{ljk} \cdot \exp(- \Vert \frac{V - V_{ljk}}{b} \Vert^2_2)
	\end{equation*}
	\vspace{.5cm}
	\begin{itemize}
		\item[$K$ - ] cluster
		\item[$w_{ljk}$ - ] is determined by offset vectors ended in the cluster $k, k \in K$
		\item[$V_{ljk}$ - ] cluster center
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Pose Estimation}

	\begin{equation*}
		p_j(x | D) \propto \sum\limits_{(x_j, w_j) \in X_j}^{} w_{j} \cdot \exp(- \Vert \frac{x - x_j}{b_j} \Vert^2_2)
	\end{equation*}
	
	\vspace{1cm}

	\begin{itemize}
		\item[$X_j$]$= \{(x_j, w_j)\}$
		\item[]
		\item[$x_j$ - ] absolute joint position, $x_j = q + V_{ljk}$
		\item[$w_j$ - ] confidence value, $w_j = w_{ljk} \cdot D^2(q)$
	\end{itemize}
	
	\vspace{0.5cm}
	
	The cluster with the highest summed weights $w_j$ are used for prediction.
\end{frame}

\begin{frame}
	\frametitle{Occlusion Aware Regression Forests}
	\textbf{idea:} Add new class labels which does not correspond to the body.
	The assumption is that if a person is interacting with a specific object, some joint positions could be predicted.
	 
	\begin{equation*}
		Q = Q \cup \{(q_{occ}, D, C_{occ}, \{v_{jocc}\})\}
	\end{equation*}
	
	\vspace{.5cm}
	\begin{columns}
		\begin{column}{.5\textwidth}
			\begin{center}
				without Semantics
			\end{center}
			\begin{equation*}
				C_{occ} = \{c_{occ}\}
			\end{equation*}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
				with Semantics
			\end{center}
			\begin{equation*}
				C_{occ} = \{c_{obj1}, c_{obj2}, ...\}
			\end{equation*}
		\end{column}
	\end{columns}
	\vspace{.5cm}
	\begin{columns}
		\begin{column}{.33\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/oarf1.png}
			\end{figure}
		\end{column}
		\begin{column}{.33\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/oarf2.png}
			\end{figure}
		\end{column}
		\begin{column}{.33\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/oarf3.png}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\subsubsection{Trainingsdata}
\begin{frame}
	\frametitle{Training Data}
	\Large
	Synthetic Data (552 images)
	\begin{itemize}
		\item Human Poses from CMU-Database \cite{cmuDataset}
		\item body part labels for each pixel
	\end{itemize}
	\vspace{1cm}
	Real Data (552 images)
	\begin{itemize}
		\item Kinect2 SDK, all fails are discarded
	\end{itemize}
\end{frame}

\subsubsection{Results}

\begin{frame}
\frametitle{With And Without Semantics}
	\begin{columns}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/res2.png}
			\end{figure}
			\begin{center}
				without semantics: the joint at the hip is not good estimated
			\end{center}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/res1.png}
			\end{figure}
			\begin{center}
				with semantics
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
\frametitle{OARF vs. Kinect2 SDK}
	\begin{columns}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/res3.png}
			\end{figure}
			\begin{center}
				Kinect2 SDK
			\end{center}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/res1.png}
			\end{figure}
			\begin{center}
				OARF with semantics
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Results}
	
	\begin{tabular}{c|c|c|c}
		& Occluded Joints & Non Occluded Joints & All Joints \\
		\hline
		OARF W/O & 32.60 & 55.50 & 50.66 \\
		OARF W   & 35.77 & 56.01 & 51.72 \\
		Kinect2 SDK & 18.13 & 66.36 & 56.94 \\
	\end{tabular}
	\begin{center}
		in $\%$
	\end{center}
	
	\vspace{1cm}
	Testset: real + synthetic data
	\begin{itemize}
		\item real data was taken with the Kinect
		\item synthetic data is generated by rendered scenes
	\end{itemize}
\end{frame}

\subsection{Occlusion Patterns}
{\setbeamercolor{background canvas}{bg=light-gray}
\begin{frame}
	\frametitle{Occlusion Patterns for Object Class Detection}
	\Large
	
		\begin{figure}
			\includegraphics[width=.8\textwidth]{img/p2h2.png}
		\end{figure}
		\begin{figure}	
			\includegraphics[width=.8\textwidth]{img/p2h1.png}
		\end{figure}
		
	\begin{align*}
		\textcolor{blue}{Input}&:  \text{Single RGB-Image} \\
		\textcolor{purple}{Output}&: \text{Object-Bounding-Boxes}
	\end{align*}
\end{frame}}

\subsubsection{Introduction}
\begin{frame}
	\frametitle{Deformable Models Approch}
	\large
	\begin{itemize}
		\item Consider each object as a deformed version of a template
		\item Compact representation
	
	\item[] \begin{figure}
		\includegraphics[width=6.0cm]{img/dpmMot.png}
		\caption{Pictorial Structure Model \cite{dpmMot}}
	\end{figure}
	
	\item[] Matching model to image involves joint optimization of part locations "stretch and fit"
	\end{itemize}
\end{frame}

\subsubsection{Algorithm}
\begin{frame}
	\frametitle{Model}
	\large
	Model is represented by a Graph
	\begin{itemize}
		\item $p = \{p_0, ..., p_M\}$ are the parts
		\item $p_i$ is parameterized through their bounding box $(l_i, r_i, t_i, b_i)$
		\item[$E_c$ - ] is the Energy function
	\end{itemize}
	
	\begin{figure}
		\begin{tikzpicture}[scale=0.8,
							ball/.style = {circle, draw, text width=1cm, align=center, inner sep=0pt}]
			\node[ball] (p0) at (0, 0) {$p_0$};
			\node[ball] (p1) at (-2, -2) {$p_1$};
			\node[ball] (p2) at (0, -2) {$p_2$};
			\node[ball] (p3) at (2, -2) {$p_3$};
			
			\draw[-,thick,draw=black!50] (p0.south west) to (p1.north);
			\draw[-,thick,draw=black!50] (p0.south) to (p2.north);
			\draw[-,thick,draw=black!50] (p0.south east) to (p3.north);
		\end{tikzpicture}
	\end{figure}
	
	\begin{align*}
		E_c(p; I) = &\underbrace{\sum\limits_{i = 0}^{M}\langle v^c_i, \Phi(p_i; I) \rangle} + &&\underbrace{\sum\limits_{i = 1}^{M} \langle w^c_i, \Phi(p_0, p_i) \rangle} \\
		&\text{placing cost} && \text{deformation cost} \\
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{Filter}
	\begin{columns}
		\begin{column}{0.6\textwidth}
			\begin{itemize}
				\item images with bounding boxes
				\item histograms of oriented gradients (HOG) for placement
				\item twice the resolution for every level
				\item Gaussians for deformation
			\end{itemize}
		\end{column}
		\begin{column}{0.4\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/exa.png}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{KITTI Data Set}
	\Large
	\begin{center}
		KITTI contains 7481 images
	\end{center}
	\begin{tabular}{c|c|c|c}
		& $\#$objects & $\#$occluded objects & $\%$ \\
		\hline
		Car & 28521 & 15231 & 53.4 \\
		Pedest. & 4445 & 1805 & 40.6 \\
		Cycles & 1612 & 772 & 44.5 \\
	\end{tabular}
	\vspace{1cm}

	Parts: 
		\begin{align*}
			\text{\textcolor{blue}{visible} } & 6 \\
			\text{\textcolor{blue}{occluded} } & 16-15 &&\\
		\end{align*}
\end{frame}

\begin{frame}
	\frametitle{Single-Object Occlusion Patterns - OC-DPM}
	\Large
	Learn class from object instances with distinctive appearances of occlusion.	
	\large
	\begin{columns}
		\begin{column}{.5\textwidth}
			\\
			\vspace{.5cm}
			$C = \{1, ..., C_{visible}\} \cup C_{invisble}$ 
			\begin{figure}
				\begin{tikzpicture}[scale=0.9,
									ball/.style = {circle, draw, text width=1cm, align=center, inner sep=0pt}]
					\node[ball] (p0) at (0, 0) {$p_0$};
					\node[ball] (p1) at (-2, -2) {$p_1$};
					\node[ball] (p2) at (0, -2) {$p_2$};
					\node[ball] (p3) at (2, -2) {$p_3$};
					
					\draw[-,thick,draw=black!50] (p0.south west) to (p1.north);
					\draw[-,thick,draw=black!50] (p0.south) to (p2.north);
					\draw[-,thick,draw=black!50] (p0.south east) to (p3.north);
				\end{tikzpicture}
			\end{figure}
			\begin{itemize}
				\item like standard DPM
				\item trained with occlusion
				\item $C$ are components
			\end{itemize}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{figure}
				\includegraphics[width=\textwidth]{img/exa.png}
			\end{figure}
		\end{column}
	\end{columns}
	
\end{frame}

\begin{frame}
	\frametitle{Double-Objects With Joint Root - SYM-DPM}
	\large
	Represent occluder and occludee at once and combine them with a root joint.
	\abovedisplayskip=0pt
	\begin{align*}
		E'_c(p; I) = \langle v^c, \Phi(p_0; I) \rangle 
					&+ \langle \overline{w}^c, \Phi(p_{0}, \overline{p}_0) \rangle 
					&&+ \langle \underline{w}^c, \Phi(p_{0}, \underline{p}_0) \rangle \\
				    &+ E_c(\overline{p}_0; I) 
				    &&+ E_c(\underline{p}_0; I) \\
	\end{align*}
	
	\begin{columns}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.6},
									ball/.style = {circle, draw, text width=0.7cm, align=center, inner sep=0pt}]
					\node[ball] (p0) at (0, 0) {$p_0$};
					\node[ball] (p1) at (-2, -2) {$\overline{p}_0$};
					\node[ball] (p2) at (2, -2) {$\underline{p}_0$};
					\node[ball] (p3) at (-3, -3.5) {$\overline{p}_1$};
					\node[ball] (p4) at (-2, -3.5) {$\overline{p}_2$};
					\node[ball] (p5) at (-1, -3.5) {$\overline{p}_3$};
					\node[ball] (p6) at (1, -3.5) {$\underline{p}_1$};
					\node[ball] (p7) at (2, -3.5) {$\underline{p}_2$};
					\node[ball] (p8) at (3, -3.5) {$\underline{p}_3$};
					
					\draw[-,thick,draw=black!50] (p0.south west) to (p1.north);
					\draw[-,thick,draw=black!50] (p0.south east) to (p2.north);
					
					\draw[-,thick,draw=black!50] (p1.south west) to (p3.north);
					\draw[-,thick,draw=black!50] (p1.south) to (p4.north);
					\draw[-,thick,draw=black!50] (p1.south east) to (p5.north);
					
					\draw[-,thick,draw=black!50] (p2.south west) to (p6.north);
					\draw[-,thick,draw=black!50] (p2.south) to (p7.north);
					\draw[-,thick,draw=black!50] (p2.south east) to (p8.north);
				\end{tikzpicture}
			\end{figure}
			\begin{itemize}
				\item one root part
				\item occluder $\overline{p}_0$ root part
				\item occludee $\underline{p}_0$ root part
			\end{itemize}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{figure}
				\includegraphics[width=.8\textwidth]{img/exa2.png}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Double-Objects Without Joint Root - ASYM-DPM}
	\large
	Both objects are combined to one, based on the intuition that the occluder can be trusted more.
	\begin{columns}
		\begin{column}{.5\textwidth}
			\begin{figure}
				\begin{tikzpicture}[scale=0.9,
									ball/.style = {circle, draw, text width=0.7cm, align=center, inner sep=0pt}]
					\node[ball] (p1) at (-2, 0) {$\overline{p}_0$};
					\node[ball] (p2) at (2, -1) {$\underline{p}_0$};
					\node[ball] (p3) at (-3, -1.5) {$\overline{p}_1$};
					\node[ball] (p4) at (-2, -1.5) {$\overline{p}_2$};
					\node[ball] (p5) at (-1, -1.5) {$\overline{p}_3$};
					\node[ball] (p6) at (1, -2.5) {$\underline{p}_1$};
					\node[ball] (p7) at (2, -2.5) {$\underline{p}_2$};
					\node[ball] (p8) at (3, -2.5) {$\underline{p}_3$};
					
					\draw[-,thick,draw=black!50] (p1.east) to (p2.west);
					
					\draw[-,thick,draw=black!50] (p1.south west) to (p3.north);
					\draw[-,thick,draw=black!50] (p1.south) to (p4.north);
					\draw[-,thick,draw=black!50] (p1.south east) to (p5.north);
					
					\draw[-,thick,draw=black!50] (p2.south west) to (p6.north);
					\draw[-,thick,draw=black!50] (p2.south) to (p7.north);
					\draw[-,thick,draw=black!50] (p2.south east) to (p8.north);
				\end{tikzpicture}
			\end{figure}
			\begin{itemize}
				\item occluder left, occludee right
				\item tree structure
				\item no extra terms
			\end{itemize}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{figure}
				\includegraphics[width=.9\textwidth]{img/exa3.png}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Mining Training Data}
	\Large
	Feature Space: \\
	\begin{itemize}
		\item[i]   occluder left/right of occludee
		\item[ii]  orientation of occluder/occludee
		\item[iii] occluder is/is not occluded
		\item[iv] degree of occlusion of occludee
 	\end{itemize}
 	\vspace{1cm}
 	Rule-based clustering
 	\begin{itemize}
	 	\item[-] repeatly splitting the training data
	 	\item[-] according to the viewing angle of the occluder
 	\end{itemize}
\end{frame}

\subsubsection{Trainingsdata}
\begin{frame}
	\frametitle{Mining Training Data}
	\begin{figure}
	\includegraphics[width=0.7\textwidth]{img/dpmoc_2.png}
	\end{figure}
\end{frame}



\subsubsection{Results}
\begin{frame}
	\frametitle{Results}
	\begin{figure}
		\includegraphics[width=\textwidth]{img/dpmoc_1.png}
	\end{figure}
	
	OC-DPM \hfill DPM
	\vspace{0.3cm}
	\begin{tabular}{c|c|c|c|c}
	    & DPM & OC-DPM & SYM-DPM & ASYM-DPM \\
		\hline
		full dataset & 62.8 & 64.4 & 53.7 & 52.3 \\
		Pedestrian & 36.2 & 37.2 & 31.4 & 29.4 \\
	\end{tabular}
	\begin{center}
		in $\%$
	\end{center}
\end{frame}

\subsection{Robust Instance Recognition}
{\setbeamercolor{background canvas}{bg=light-gray} 
\begin{frame}
	\frametitle{Robust Instance Recognition in Presence of Occlusion and Clutter}	
	\begin{figure}
		\includegraphics[width=.5\textwidth]{img/p3h1.png}
	\end{figure}
	
	\begin{align*}
		\textcolor{blue}{Input}&:  \text{5-10 consecutive frames as one Pointcloud} \\
		\textcolor{purple}{Output}&: \text{6D-Object-Pose}
	\end{align*}
\end{frame}}

\subsubsection{Introduction}
\begin{frame}
	\frametitle{Intoduction}
	\Large
	\begin{itemize}
		\item[-] object shape is invariant to changes in illumination or texture
		\item[-] Kinect sensors generates cheap depth data
		\item[-] it is easy to synthesize pointcloud data
	\end{itemize}
\end{frame}

\subsubsection{Algorithm}
\begin{frame}
	\frametitle{Edgelet}
	
	\begin{columns}
		\begin{column}{0.8\textwidth}
			\begin{itemize}
				\item $N$ points per Pointcloud $j$
				\item \textcolor{Maroon}{FOR ALL} $i \in \{1, ..., N\}$
						\begin{itemize}
							\item calc $\lambda_1$ and $\lambda_2$
							\item $r = \frac{\lambda_1}{\lambda_2}$
							\item $r \rightarrow$ \textcolor{MidnightBlue}{curvatureMap}
						\end{itemize}
				\item hysteresisThesholding(\textcolor{MidnightBlue}{curvatureMap});
				\item nonmaximalSuppression(\textcolor{MidnightBlue}{curvatureMap});
				\item hysteresisThesholding(\textcolor{MidnightBlue}{depthMap});
				\item projectToPointcloud(\textcolor{MidnightBlue}{curvatureMap}, \textcolor{MidnightBlue}{depthMap});
				\item RANSAC line fitting
				\item orientation to 8 bins\textcolor{OliveGreen}{// (direction$\% \pi$)}
			\end{itemize}
		\end{column}
		\begin{column}{0.2\textwidth}
			\begin{figure}
				\begin{tikzpicture}[scale=0.7,
									ball/.style = {circle, fill=black!70, text width=0.1cm}]
					\node[ball] (p1) at (-.5, 5) {};
					\draw[->,ultra thick,draw=black!70] (p1.north east) to (.5,6);
				\end{tikzpicture}
			\end{figure}
			\begin{figure}
				\begin{tikzpicture}[scale=.9]
					\draw (0, 0) ellipse (1 and 1) node[below] {X};
					\draw (-1, 0) node[left]{$\pi$} -- (1, 0)  node[right]{0};
					\draw (0, 0) -- (0, 1)  node[above]{$\frac{\pi}{2}$};
					\draw (0, 0) -- (.7, .7);
					\draw (0, 0) -- (.92, .38);
					\draw (0, 0) -- (.38, .92);
					\draw (0, 0) -- (-.7, .7);
					\draw (0, 0) -- (-.92, .38);
					\draw (0, 0) -- (-.38, .92);
				\end{tikzpicture}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Feature Vector}
	\large
	\begin{columns}
		\begin{column}{.3\textwidth}
			\begin{equation*}
				w \times h \times d
			\end{equation*}
			\begin{figure}
				\begin{tikzpicture}[x={(1cm,0cm)},y={(0cm,1cm)}, z={(0.4cm,0.3cm)}, scale=0.5]
					\def\d{2}
					\foreach \x in {-\d, ...,\d} {
						\draw (\x, -\d, -\d) -- (\x, \d, -\d);
						\draw (\x, \d, -\d) -- (\x, \d, \d);
					}
					
					\foreach \y in {-\d, ...,\d} {
						\draw (-\d, \y, -\d) -- (\d, \y, -\d);
						\draw (\d, \y, -\d) -- (\d, \y, \d);
					}
					
					\foreach \z in {-\d, ...,\d} {
						\draw (-\d, \d, \z) -- (\d, \d, \z);
						\draw (\d, -\d, \z) -- (\d, \d, \z);
					}
					\draw[->,ultra thick,draw=black!50] (-.4, 0) to [out=270,in=220] (4, 3);
				\end{tikzpicture}
			\end{figure}
		\end{column}
		\begin{column}{.7\textwidth}
			\begin{center}
				Voxel $v$
			
				\begin{figure}
					\begin{tikzpicture}
						\draw (0, 0) -- (8, 0) -- node[left]{8}(8, -1) -- (0, -1) -- cycle;
						\draw (1, 0) -- node[left]{1} (1, -1); 
						\draw (2, 0) -- node[left]{2}node[right]{...}(2, -1);
						\draw (7, 0) -- (7, -1);
					\end{tikzpicture}
				\end{figure}
			\end{center}
			\begin{align*}
				x^v_i &= \begin{cases} 1 & \mbox{\textcolor{MidnightBlue}{if} } i \mbox{ is dominant} \\
				0 & \mbox{\textcolor{MidnightBlue}{else} } i \mbox{is not dominant}
				\end{cases} \\
				x^v &= -1 \mbox{ \textcolor{MidnightBlue}{if} v is not visible}
			\end{align*}
		\end{column}
	\end{columns}
	\vspace{1cm}
	The resulting feature vector is the concatenation of all voxels:
	\begin{equation*}
		w \times h \times d \times 8
	\end{equation*}
\end{frame}

\begin{frame}
	\frametitle{Box Model For Occluder}
	
	\begin{figure}
		\includegraphics[width=.9\textwidth]{img/occ_state.png}
	\end{figure}
	
	\begin{itemize}
		\item occluder are rectangular
		\item occluders are restricted to start from the ground plane
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Soft Label Random Forest}
	\Large
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\begin{figure}
				%	\begin{tikzpicture}[x={(1cm,0cm)},y={(0cm,1cm)}, z={(0.5cm,0.5cm)}, scale=0.5]
				%		\draw[->, >=latex] (-4,0,0) -- (4,0,0) node[below]{$x$};
				%		\draw[->, >=latex] (0,-4,0) -- (0,4,0) node[left]{$y$};
				%		\draw[->, >=latex] (0,0,4) -- (0,0,-4) node[right]{$z$};
				%		\draw[color=green,thick] (0,-3) ellipse (1 and .5);
				%		\draw[->,color=green,thick] (-1,-3) -- (-1,-2.9);
				%		\draw[->,color=green,thick] (1,-3) -- (1,-3.1) node[right]{yaw};
				%		\draw[color=blue,thick] (-.8,-.8) ellipse (.5 and .5);
				%		\draw[->,color=blue,thick] (-0.3,-.8) -- (-0.3,-.9);
				%		\draw[->,color=blue,thick] (-1.3,-.8) -- (-1.3,-.7) node[left]{roll};		
				%		\draw[color=red,thick] (3,0) ellipse (.5 and 1);
				%		\draw[->,color=red,thick] (3,1) -- (3.1,1)  node[above]{pitch};
				%		\draw[->,color=red,thick] (3,-1) -- (2.9,-1);
				%	\end{tikzpicture}
				\includegraphics[width=\textwidth]{img/occ_ori.png}
			\end{figure}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{itemize}
				\item 16 pose classes
				\item +1 class $= \begin{cases}
					1 & \mbox{if bg} \\
					0 & \mbox{else}
					\end{cases}$
				\item $d^i_j = \lVert I - R^i_j \rVert_F$
			\end{itemize}
		\end{column}
	\end{columns}
	\begin{align*}
		l^i_j &= \exp ({-d^i_j}^2), i \in \{1, ...,16\} \\
		\text{\textcolor{Maroon}{IF} fg \textcolor{Maroon}{THEN} }1 &= \sum\limits_{i = 1}^{16} l^i_j \text{ \textcolor{Maroon}{ELSE} 0 }
	\end{align*}
\end{frame}

\begin{frame}
	\frametitle{Occlusion Queries}
	\Large
	\begin{center}
		$x_j \in \{-1, 0, 1\}$
	\end{center}
	\begin{columns}
		\begin{column}{.3\textwidth}
		\end{column}
		\begin{column}{.7\textwidth}
			\begin{itemize}
				\item[$(> -1)$ - ] visible versus occluded voxel
				\item[$(>  0)$ - ] if greater $0$ the voxel is dominant
			\end{itemize}
		\end{column}
	\end{columns}
	
	\vspace{.5cm}
	\begin{itemize}
		\item[-] split questions in the topmost nodes $(\approx 5 - 10)$ are restricted to the second type
		\item[-] training set consists of 27000 simulated views
	\end{itemize}
\end{frame}

\begin{frame}
\frametitle{training scheme for sLRF}

\large

\textcolor{Maroon}{Input}: $X = \{x_j, l_j\}$ \\
\textcolor{Blue}{Output}: Learnt sLRF classifier

\begin{enumerate}
	\item $X_s \subset X$, $\lvert X_s \rvert = \lvert X \rvert / 20$
	\item Train sLRF with $X_s$, compute $p_{fg}$ with X
	\item add borderline positive (low $p_{fg}$) and borderline negativ (high $p_{fg}$)
	\item add confusing samples
	\item compute $d_L$ for all positive samples, add samples with high $d_L$
	\item repeat 2-5 till $p_{fg}$ for all positive data is greater than $p_{fg}$ for all negative data.
\end{enumerate}

\end{frame}

\begin{frame}
	\begin{figure}
	\includegraphics[width=10cm]{img/rir_1.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Results}
	
	\begin{center}
		\small
		\begin{tabular}{c|c|c|c|c}
			& D-DPM & LineMod & S-Iterative (Edges) & S-Iterative (Occlusion) \\
			\hline
			L & 40.50 & 30.15 & 70.70 & 81.89 \\
			L+P & 23.72 & 13.17 & 52.62 & 62.11 \\
		\end{tabular}
		in $\%$
		\begin{itemize}
			\item[L - ] location
			\item[P - ] pose estimation
		\end{itemize}
	\end{center}
\end{frame}

\section{Conclusions}
\begin{frame}
	\frametitle{Robustness Against Occlusion - Conclusion}
	\Large
	\begin{itemize}
		\item semantic (scene understanding)
		\item mixture models
		\item multiple representation for one object class
		\item good feature representation
		\item training with occlusion
	\end{itemize}
\end{frame}

\section{Discussion}
{\setbeamercolor{background canvas}{bg=MidnightBlue} \setbeamercolor{titlelike}{fg=white}
\begin{frame}
	\frametitle{Discussion}
	\begin{center}
		{\fontsize{120}{48} \selectfont \textcolor{white}{?}}
	\end{center}
\end{frame}}

\section{References}
\begin{frame}[t,allowframebreaks]
	\nocite{*}
	\printbibliography
\end{frame}

\end{document}
